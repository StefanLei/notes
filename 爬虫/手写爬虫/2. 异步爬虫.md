

```python
import asyncio
import aiohttp
import json
import json
from lxml import etree
import re


async def fetch(session, url):
    headers = {'content-type': 'application/json'}

    async with session.get(url, headers=headers) as response:
        html = await response.text()
        
        # return 的数据会返回给上一个 协程。最终返回到 loop.run_until_completa()
        return await parse(html)


async def main(url):
    # cookies 是在这里设置的
    cookies = {'cookies_are': 'working'}
    async with aiohttp.ClientSession(cookies=cookies) as session:
        return await fetch(session, url)


async def parse(data):
    title = re.search('(?<="title":").*(?=","released_at")', data).group()
    return title


url_list = ("https://sspai.com/api/v1/articles?offset={}&limit=1".format(offset) for offset in range(100))

coroutines = (main(url) for url in url_list)

loop = asyncio.get_event_loop()

# 这里的结果就是协程返回来的，我们可以在这里一次性处理，或者在协程的函数中，一条一条处理。
result = loop.run_until_complete(asyncio.gather(*coroutines))

print(result)
```

