### Spark 容错机制

[参考链接](https://www.jianshu.com/p/99ebcc7c92d3)

一般来说，分布式数据集的容错性有两种方式：==数据检查点和记录数据的更新==

面向大规模数据分析，数据检查点操作成本很高，需要通过网络复制大量的数据集。

因此，Spark 采用==记录数据的更新的方式==（也配合使用检查点 checkpoint 机制），但是更新粒度太细太多，那么记录更新成本也不低。

因此，RDD 只支持粗粒度转换，即只记录单个块上执行的单个操作，然后将创建的RDD的一系列变换序列记录下来。（每个RDD都包含了，它是如何由其他RDD变换过来的，以及如何重建某一==分区==的数据信息。因此RDD的容错机制又称为“血统”）

Lineage本质上很类似于数据库中的重做日志（Redo Log），只不过这个重做日志粒度很大，是对全局数据做同样的重做进而恢复数据。 

---

### Lineage 机制

#### Lineage 简介

相比其他系统的细粒度的内存数据更新级别的备份或者LOG机制，RDD的 Lineage 记录的是粗粒度的特定数据Transformation操作（==如 filter，map，join 等==）行为。当这个RDD的部分分区数据丢失时，它可以通过Lineage获取足够信息来重新的运算和恢复失去的数据分区。因为这种粗颗粒的数据模型，限制了Spark的运用场合，所以Spark并不适用于所有高性能要求的场景，但同时相比细颗粒度的数据模型，也带来了性能的提升。 

#### 两种依赖关系

依赖指的是，每一个RDD都依赖于上一个RDD。

在Spark中，依赖分为两种：窄依赖（Narrow Dependencies ）和宽依赖（Wide Dependencies ），源码中称为 Shuffle Dependencies ，用来解决数据容错的高效。

![](../图片资料/834652-20170505111446836-1148820620.png)

- 窄依赖就是，一个分区只有一个出去的箭头。
- 宽依赖就是，一个分区有多个出去的箭头。

##### 本质理解

根据父RDD分区是对应1个还是多个子RDD分区来划分==窄依赖（父分区对应一个子分区）==和==宽依赖（一个父分区对应多个子分区）==