### HDFS 读写流程

#### HDFS 读文件

![](https://upload-images.jianshu.io/upload_images/11096896-f642dca06447aa05.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



- 首先客户端会有一个 open 方法，通过这个方法来读取指定的文件，这个文件在 HDFS 中，就是一个 distributerfilesystem对象实例。
- 然后 distributerfilesystem 会以 RPC 的方式调用 namenode , namenode会返回块信息。对于每一个块来说，namenode 会返回包含当前块所有副本的 datanode 地址。同时 datanode 地址会根据距离客户端的，进行排序（网络拓扑）。如果这个客户端本身就是一个 datanode（比如 mapreduce 任务的时候） ，那么该客户端就会从本地的 datanode 上读取数据。
- 然后这个 DistributedFIleStream 实例，会返回一个 FSDataInputStream 对象，以便给客户端读取数据，然后这个 FSDataFileStream 对象又会被封装成 DFSInputStream 。
- 然后客户端调用 DSFInputStream 的 read() 方法，DFSInputStream 就会去连接文件所在的第一个 block 块的 datanode ，通过反复调用 read（）方法，就可以将数据从 datanode 传输到客户端来。
- 当到达块末尾的时候，DFSInputStream 关闭与该 datanode 的连接，然后寻找下一个块的最佳 datanode 位置。一直重复下去
- 客户端也会根据需要询问namenode下一批数据块的datanode地址，一旦客户端读取完毕，就对 FSDataInputStream调用 close() 方法。 
- 所有的的这些对客户端都是透明的，在客户端看来就是一个连续的流。

注意：

在读取数据的时候，如果 DFSInputStream 在与 datanode 通信的时候，遇到错误，会尝试从这个块的另外一个最邻近的 datanode 读取数据。它也会记住那个故障的 datanode，保证以后，不会反复读取该节点上的数据。

DFSinputStream 也会校验从 datanode 发来的数据是否完整，如果发现有损坏的块，DFSinputStream 会试图从其他 Datanode 读取其复本，也会讲被损坏的块通知给 namenode.

---

#### HDFS 写文件

![](http://i2.51cto.com/images/blog/201805/22/db1cb7e696ec9895cf40a10187afb06d.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_100,g_se,x_10,y_10,shadow_90,type_ZmFuZ3poZW5naGVpdGk=)



- 客户端会调用 distributerfilesystem 的 create() 方法。

- 然后 distributerfilesystem 会以 RPC 的方式调用 namenode，在命名空间中新建一个文件，此时该文件中还没有block块。namenode会执行各种不同的检查，以确保这个文件不存在，以及客户端有创建文件的权限。如果这些检查都通过了，namenode就会创建一个新文件的记录，否则文件创建失败，并抛出一个异常。distributerfilesystem 会向客户端返回一个FSDataOutputStream 对象，客户端可以通过这个对象写入数据，

  这个对象封装了一个 DFSoutPutStream 对象。通过调用这个对象的 write 来写入数据

- 在写入数据的时候，DSFoutputStream 将它分成一个个的数据包，并写入内部队列，称为数据队列。DataStreamer 处理数据队列（DataStreamer 请求分配数据块），它的职责是挑选出合适的用来储存复本的一组 datanode。这一组 datanode 构成了一个管道。假设我们设置的复本数是3，那么管道的节点数就是 3 ， DataStreamer 将数据包流式传输到管道的第一个节点上，该节点储存数据并将它发送到第二个节点。同样，第二个 datanode 储存该数据包并同时发给管道的第3个节点上。DSFoutputStream 内部也维护着一个数据包队列，来对待 datanode 的收到的确认回执，称为 “ 确认队列”(ACK queue) 。确认队列中的数据和数据队列中的一样，DFSOutPutStream 收到管道中所有的DataNode的确认信息后，才会把数据从队列里面删除。

- 如果任何 datanode 在数据写入的时候，发送故障，那么首先关闭管道，然后把确认队列中的数据都添加到数据队列的最前端，以保证下游节点不会漏掉任何一个数据包。