##### 下载并解压

```sh
tar -zxvf kafka.taz
```

##### 配置 config 目录下的 server.properties 文件

```properties
# 这配置的时kafka序号，每台的需要都不一样，按顺序 0 1 2 3.
broker.id=0

# 这里配置的是 kafka 数据文件的位置，不是日志文件
log.dirs=/root/kafka-logs

# 这里配置的是 zookeeper 的地址。
zookeeper.connect=hadoop1:2181,hadoop2:2181,hadoop3:2181

# 是否允许删除主题
delete.topic.enable=true
```

==其他的配置按需要修改==



##### 将kafka文件夹发到其他的服务器上

```
scp -r kafka hadoop2:`pwd`
```

##### 启动 zookeeper

```sh
zkServer.sh start
```

##### 然后再每一个服务器上，手动启动 kafka

```
kafka-server.start.sh config/server.preperties
```

---



#### kafka 使用

- 首先需要创建一个 topic 

```sh
# 指定一个 zookeeper 就行，副本数和分区数是必须的
kafka-topics.sh --zookeeper hadoop1:2181 --topic test --replication-factor 2 --partitions 5 --create
```

- 然后使用生产者向这个主题里面添加数据

```sh
kafka-console-producer.sh --broker-list hadoop1:9092,hadoop2:9092,hadoop3:9092,hadoop4:9092 --topic test
```

- 然后使用消费者消费

```sh
# 从头开始消费，就是获取 kafka 里面所有的数据 （数据是乱的，出非只有一个分区）
kafka-console-consumer.sh --zookeeper hadoop1:2181 --from-beginning --topic test

# 从当前时间点开始消费，就是说，现在开始，有生产者生产新的数据，那消费者就消费新的数据
kafka-console-consumer.sh --zookeeper hadoop1:2181  --topic test
```

---

#### 常用命令

> 创建主题

```sh
kafka-topics.sh --zookeeper hadoop1:2181 --topic test --replication-factor 2 --partitions 5 --create
```

> 查看主题

```sh
kafka-topics.sh --zookeeper hadoop1:2181 --list
```

> 删除主题（标记删除）

```sh
kafka-topics.sh --zookeeper hadoop1:2181 --topic test --delete
```