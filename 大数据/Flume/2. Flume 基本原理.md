### Flume 介绍

[参考链接](https://www.cnblogs.com/zhangyinhua/p/7803486.html)

Flume是一个分布式、可扩展、可靠、高可用的海量日志有效聚合及移动的框架。 它通常用于log数据，支持在系统中定制各类数据发送方，用于收集数据。它具有可靠性和容 错可调机制和许多故障转移和恢复机制

#### Flume 1.0x   ( Flume NG )

==Flume 1.0x 版本中 Flume 只有 agent ，由3个部分组成==

> Flume 运行的核心是 Agent。

Flume 以 agent 为==最小的独立运行单位==。一个agent就是一个JVM。它是一个完整的数据收集工具，含有三个核心组件，分别是 source、 channel、 sink。

通过这些组件， Event 可以从一个地方流向另一个地方，如下图所示。

![](https://images2017.cnblogs.com/blog/999804/201711/999804-20171108130603872-780242084.png)

---



#### 基本概念

`Client`：Client生产数据，运行在一个独立的线程。 

`Event`： 一个数据单元，消息头和消息体组成。（Events可以是日志记录、 avro 对象等） 　　

`Flow`： Event从源点到达目的点的迁移的抽象。 



`Agent` : 一个独立的 Flume 进程，包含组件  `source`,`channel`,`sink` ( Agent 使用 JVM 运行 Flume )，每个机器运行			 一个独立的 Agent ，但是可以在一个 Agent 中包含多个 `sources`和`sinks`

`Source` : 数据收集器 （source 从 client 手机数据，传递给 channel ）

`Channel`: 中转一个 Event 的临时储存，保存由 Source 组建传递来的 `Event`,（Channel连接 sources 和 sinks ，这个有点像一个队列。） 

`Sink`: 从`Channel`中读取并移除 Event ，将 Event 传递到FlowPipeline中的下一个Agent（如果有的话）（Sink从Channel收集数据，运行在一个独立线程。） 

---



### Flume 特点

- flume 的数据流由事件(Event)贯穿始终。事件是 Flume 的基本数据单位，它携带日志数据(字节数组形式)并且携带有头信息，这些Event由Agent外部的Source生成，当

- Source 捕获事件后会进行特定的格式化，然后 Source 会把事件推入(单个或多个)Channel中。你可以把Channel看作是一个缓冲区，它将保存事件直到Sink处理完该事件。

- Sink 负责持久化日志或者把事件推向另一个 Source。

> 可靠性

当节点出现故障时，日志能够被传送到其他的节点上，而不会丢失。Flume 提供了3种级别的可靠性保障，从强到弱依次分别为：

- end-to-end 收到数据后 agent 首先将数据（event）写入到磁盘上，当数据传送成功后，再删除。如果数据发送失败，可以重新发送。
- Store on failure 这是 scribe 采用的策略，当数据接受方 crash （死机）时，将数据写到本地，待恢复后，继续发送.
- Besteffort 数据发送方，发送数据后，就不管了。

> 自身可扩展性

Flume 采用了三层架构，分别为 agent，collector和storage，每一层均可以水平扩展。所有agent 和 collector由master统一管理，使得系统容易监控和维护。master允许有多个（使用ZooKeeper进 行管理和负载均衡），避免单点故障问题。（1.0自身agent实现扩展）

> 功能可扩展性

用户可以根据自己的需要添加自动的 agent

Flume 自带了很多的组件，包括各种 agent (file, syslog, HDFS 等)

---



### Flume 安装

> 将下载的 flume 包，解压，配置 FLUME_HOME 环境变量


`tar -zxvf flume.tar.gz`


> 修改  flume-env.sh 配置文件，主要就是配置 JAVA_HOME

##### flume-env.sh  就是配置环境变量


`export JAVA_HOME=/opt/jdk1.8.0_171`

##### 验证是否安装成功

`flume-ng version`

---



### Flume 使用

##### 使用 netcat 进行验证

```shell
# 安装 telnet
yum list telnet* 
yum install telnet-server
yum install telnet-client
```



##### 编辑具体的配置文件 netcat_logger ( 配置文件的位置任意，在启动服务的时候指定就行 )

```ini
# example.conf: A single-node Flume configuration

# Name the components on this agent
# 这里是定义 source channels sinks 名字
a1.sources = r1
a1.sinks = k1
a1.channels = c1

# Describe/configure the source
# 这里是定义 source 监听的数据类型，
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

# Describe the sink
# 这里是定义 sinks 输出的类型
a1.sinks.k1.type = logger

# Use a channel which buffers events in memory
# 这里是指定 channels 一些信息
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

# Bind the source and sink to the channel
# 这里是指定3者之间的连接关系
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

##### 在命令行中启动 Flume

```shell
flume-ng agent --config-file /root/netcat_logger --name a1 -Dflume.root.logger=INFO,console

--config-file 指定配置文件位置
--name        指定配置文件中哪个 agent 
-Dflume.root.logger=INFO,console 指定日志等级和输出的位置 （默认是输出到控制台）
```

##### 在另一个命令行中发送数据

`telnet localhost 44444`

IP和端口，由之前的配置文件决定

---

### source 解释

Source是数据的收集端，负责将数据捕获后进行特殊的格式化，将数据封装到事件（event） 里，然后将事件推入Channel中。 Flume提供了很多内置的 　　Source， 支持 Avro， log4j， syslog 和 http post(body为json格式)。可以让应用程序同已有的Source直接打交道，如AvroSource， 　　SyslogTcpSource。 如果内置的Source无法满足需要， Flume还支持自定义Source。 

![](https://images2017.cnblogs.com/blog/999804/201711/999804-20171108130818481-670496307.png)

##### source 支持的类型

![](https://images2017.cnblogs.com/blog/999804/201711/999804-20171108130931325-512757774.png)

### channel 详解

Channel是连接Source和Sink的组件，大家可以将它看做一个数据的缓冲区（数据队列），它可以将事件暂存到内存中也可以持久化到本地磁盘上， 直到Sink处理完该事件。介绍两个较为常用的Channel， MemoryChannel和FileChannel。 

![](https://images2017.cnblogs.com/blog/999804/201711/999804-20171108131248653-2068131817.png)

### sink 详解

Sink从Channel中取出事件，然后将数据发到别处，可以向文件系统、数据库、 hadoop存数据， 也可以是其他agent的Source。在日志数据较少时，可以将数据存储在文件系统中，并且设定一定的时间间隔保存数据。 

![](https://images2017.cnblogs.com/blog/999804/201711/999804-20171108131438466-1752568401.png)

![](https://images2017.cnblogs.com/blog/999804/201711/999804-20171108131516809-1930573599.png)