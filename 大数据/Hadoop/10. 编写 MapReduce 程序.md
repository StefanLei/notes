###   编写 MapReduce 程序

在 Python 中我们使用 MRJob 来运行 MapReduce 程序

```python
from mrjob.job import MRJob


class WordCount(MRJob):
    def mapper(self, key, line):
        # 这里传进来的是一行数据
        words = line.split()
        for word in words:
            yield word, 1

    def reducer(self, key, values):
        yield key, sum(values)


if __name__ == '__main__':
    WordCount.run()

```



#### 运行方式

> inline 模式

inline 模式不需要安装 Hadoop，完全由 MRJob 模块实现

特点是调试方便，启动==单一进程==模拟任务执行状态及结果，Mrjob 默认以内嵌方式运行 

```shell
# 默认就是 inline ，后面文件路径只可以是本地文件系统的路径
python3 test.py wordcount.txt
python3 test.py -r inline wordcount.txt

# Job （作业）输出文件放在本地 test 目录里面 这里面也包含了结果
python3 python_test.py -r inline /root/wordcount.txt -o test

# 把结果重定向到 test.log 文件里
python3 python_test.py -r inline /root/wordcount.txt > test.log
```



> local 模式

用于本地模拟Hadoop调试，与内嵌方式的区别是启动了多进程执行每一个任务，也不需要 Hadoop

`python3 test.py -r local wordcount.txt`



> hadoop 模式

在 Hadoop 集群上运行 ，需要 Hadoop 环境，支持Hadoop运行调度控制参数。 

使用 Hadoop 的时候，需要指定 Python 环境

```shell
# 可以是本地文件路径 也可以是 HDFS 路径
python3 test.py -r hadoop /root/wordcount.txt --python-bin /opt/Python3/bin/python3
python3 test.py -r hadoop hdfs://namenodes/wordcount.txt --python-bin /opt/Python3/bin/python32w

# 这个模式也可以重定向 重定向是保存到本地文件系统
python3 test.py -r hadoop /root/wordcount.txt --python-bin /opt/Python3/bin/python3 > test.log

# -o 是把 Job 结果保存到指定的文件夹
python3 test.py -r hadoop /root/wordcount.txt --python-bin /opt/Python3/bin/python3 -o test

```

