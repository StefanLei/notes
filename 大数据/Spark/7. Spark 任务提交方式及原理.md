#### Spark 任务提交方式

> Local 方式

==使用 local 方式，不需要提前启动 Spark==

直接在命令行提交命令就行

`spark-submit --master local test.py` 或者 `spark-submit test.py` （如果设置master默认就是local）

还可以指定线程数量

`spark-submit --master local[2] test.py`



> Standalone 方式

==使用 Standalone 方式，需要提前启动 Spark==

- 启动 Spark `./start-all.sh`

##### Standalone on client 方式  客户端模式一般用于测试

`./spark-submit.sh --master spark://hadoop1:70077 --deploy-mode client test.py`

如果不指定 --deploy-mode 默认就是 client 模式

`./spark-submit --master spark://hadoop1:7077  ../examples/src/main/python/pi.py 10`



##### Standalone on cluster 方式  

cluster 方式，不能提交 Python 代码

`./spark-submit --master spark://hadoop1:7077 --deploy-mode cluster ../examples/src/main/python/pi.py 10`

可以提交 Java 代码

`./bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://spark001:7077 --executor-memory 1G --total-executor-cores 1 ./lib/spark-examples-1.6.0-hadoop2.4.0.jar 100`



> Spark on Yarn 方式

==使用 Yarn 方式，不需要提前启动 Spark，但需要启动 Hadoop 集群==

##### Yarn on client 方式 客户端模式一般用于测试

`./spark-submit --master yarn --deploy-mode client ../examples/src/main/python/pi.py 10`

如果这里出现了错误，那么就到 Hadoop 的 yarn-site.xml 配置

```xml
   <property>
        <!--虚拟内存设置是否生效，如果为 True，那么那么当运行任务时，虚拟内存超过了，默认值，那么container会被杀死，如果为 False ，就不会被杀死-->
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
```

##### Yarn on cluster 方式

`./spark-submit --master yarn --deploy-mode cluster ../examples/src/main/python/pi.py 10`

---

### 任务提交方式原理

#### Standalone on client 原理

- client 模式提交任务后，会在客户端启动 Driver 进程
- Driver 会向 master 申请启动 Application 的资源。
- 资源申请成功以后，Driver 端将 task 发送到 worker(executor) 端执行
- worker 将 task 执行结果返回到 Driver 端。

##### Standalone on cluster 原理

- cluster 模式提交任务后，会向 master 申请启动Driver
- Master 接受请求，随机在集s群一台节点上启动 Driver 进程。
- Driver 进程启动后，会向 master 申请启动 application 的资源。
- 资源申请成功后，driver 端，将 task 发送到 worker(executor) 节点上执行。
- worker 将执行情况和结果返回给 driver 端。



#### Yarn on client 原理

- 客户端提交一个 application 后，会在客户端启动一个 Driver 进程。
- 应用程序启动后会向 resourcemanager 发送请求，要求启动一个 applicationmaster
- resourcemager 收到请求后，会根据资源使用情况，选择一个节点，启动这个节点上 application master 
- 然后这个 node manager 就会启动 application master，然后这个 application master 会向 resourcemanager请求资源
- resoucemanager 收到请求后，会通知 node manager 创建一个 container ,然后 application master 会向 node master 发送命令要求它启动 exector
- executor 启动后，会反向注册给 driver ，driver 发送task到 executor ，executor 将执行情况和结果返回给 driver端。

#### Yarn on cluster 原理

- 客户端提交了一个 application 后，会发送请求到 resoucemanager ，请求启动 application master。
- resource manager 会选择一台node manager 来启动 application master，同时会在这个节点上启动 driver。
- application master 启动后，application master 会向 resoucemanager 申请资源用于启动 execoter。
- resource manager 就会命令一批 nodemanager 创建 container，同时会返回这些 node manager 给 application master
- 然后 application master 发送请求到 node manager 请求启动 executor。
- executor 启动后，会反向注册到 appliction 所在节点的 driver，driver 发送 task 到 exeuctor

---

### 在 Spark 上运行 Python 程序。

`./spark-submit --master yarn --deploy-mode client  /root/main.py`

`./spark-submit --master yarn --deploy-mode cluster  /root/main.py`

```python
from pyspark import SparkConf, SparkContext
# 在 Spark 中运行的话，不需要在代码中指定 master。
# 要在命令行中指定
conf = SparkConf().setAppName("test")
sc = SparkContext(conf=conf)

# 这里的路径要是 HDFS 的路径
myfile = sc.textFile("/yob2017.txt")

def test(line):
    l = line.split(',')
    return l[0], int(l[2])

results = myfile.map(test).reduce(lambda a, b: a + b)
print(results)

```

